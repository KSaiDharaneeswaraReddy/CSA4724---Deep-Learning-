# ======================================================================
#  Combined Implementation:
#     1. Restricted Boltzmann Machine (RBM)
#     2. Recurrent Neural Network (RNN)
#     3. Long Short-Term Memory (LSTM)
#  Dataset:
#     - RBM: MNIST digits (scikit-learn digits)
#     - RNN/LSTM: IMDB Sentiment Dataset
# ======================================================================

# --------------------------
# 1. RESTRICTED BOLTZMANN MACHINE (RBM)
# --------------------------
print("\n==================== RBM MODEL ====================\n")

from sklearn.neural_network import BernoulliRBM
from sklearn.datasets import load_digits
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Load MNIST-like digits dataset
digits = load_digits()
X = digits.data

# Normalize data
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

# RBM Model
rbm = BernoulliRBM(n_components=64, learning_rate=0.01, n_iter=20, batch_size=10)
rbm.fit(X)

# Reconstruction
X_recons = rbm.inverse_transform(rbm.transform(X))
mse = mean_squared_error(X, X_recons)

print("RBM Reconstruction Error (MSE):", mse)


# --------------------------
# 2. RNN MODEL (IMDB)
# --------------------------
print("\n==================== RNN MODEL ====================\n")

import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Embedding

# Load IMDB dataset
num_words = 5000
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)

# Sequence Padding
max_len = 200
X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)

# Build Simple RNN
model_rnn = Sequential([
    Embedding(num_words, 32, input_length=max_len),
    SimpleRNN(32),
    Dense(1, activation='sigmoid')
])

model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
history_rnn = model_rnn.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.2)

# Evaluate
loss_rnn, acc_rnn = model_rnn.evaluate(X_test, y_test, verbose=0)
print("RNN Test Accuracy:", acc_rnn)


# --------------------------
# 3. LSTM MODEL (IMDB)
# --------------------------
print("\n==================== LSTM MODEL ====================\n")

from tensorflow.keras.layers import LSTM

# Build LSTM Model
model_lstm = Sequential([
    Embedding(num_words, 64, input_length=max_len),
    LSTM(64),
    Dense(1, activation='sigmoid')
])

model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
history_lstm = model_lstm.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.2)

# Evaluate
loss_lstm, acc_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)
print("LSTM Test Accuracy:", acc_lstm)


# --------------------------
# FINAL SUMMARY
# --------------------------
print("\n==================== FINAL RESULTS ====================\n")
print("RBM Reconstruction Error (MSE):", mse)
print("RNN Test Accuracy:", acc_rnn)
print("LSTM Test Accuracy:", acc_lstm)
