import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.datasets import load_diabetes

# -------------------------------------------------------------
# 1. Load a Numerical Database (Sklearn Diabetes Dataset)
# -------------------------------------------------------------
data = load_diabetes()
X = data.data
y = data.target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# -------------------------------------------------------------
# 2. Train Two Models
#    - Simple model: Linear Regression (low chance of overfitting)
#    - Complex model: Decision Tree (high chance of overfitting)
# -------------------------------------------------------------

# Simple model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

# Complex model
tree = DecisionTreeRegressor(max_depth=None, random_state=42)
tree.fit(X_train, y_train)

# -------------------------------------------------------------
# 3. Compute Train–Test Performance (MSE)
# -------------------------------------------------------------

# Linear Regression performance
train_pred_lr = linear_model.predict(X_train)
test_pred_lr = linear_model.predict(X_test)

# Decision Tree performance
train_pred_tree = tree.predict(X_train)
test_pred_tree = tree.predict(X_test)

# Mean Squared Errors
mse_lr_train = mean_squared_error(y_train, train_pred_lr)
mse_lr_test  = mean_squared_error(y_test, test_pred_lr)

mse_tree_train = mean_squared_error(y_train, train_pred_tree)
mse_tree_test  = mean_squared_error(y_test, test_pred_tree)

print("===== PERFORMANCE COMPARISON =====")
print("\n--- Linear Regression (Simple Model) ---")
print(f"Train MSE: {mse_lr_train:.2f}")
print(f"Test MSE : {mse_lr_test:.2f}")

print("\n--- Decision Tree (Complex Model) ---")
print(f"Train MSE: {mse_tree_train:.2f}")
print(f"Test MSE : {mse_tree_test:.2f}")

# -------------------------------------------------------------
# 4. Verification of Overfitting
# -------------------------------------------------------------

print("\n===== OVERFITTING VERIFICATION =====")
if mse_tree_train < 5 and mse_tree_test > mse_lr_test:
    print("The Decision Tree model shows strong overfitting.")
elif mse_tree_test > mse_tree_train * 1.5:
    print("The Decision Tree is overfitting (test error much larger).")
else:
    print("No clear overfitting detected.")

# -------------------------------------------------------------
# 5. Plot Learning Curves (Optional but useful)
# -------------------------------------------------------------

train_sizes = np.linspace(0.1, 1.0, 10)

train_errors = []
test_errors = []

for s in train_sizes:
    size = int(s * len(X_train))
    X_subset = X_train[:size]
    y_subset = y_train[:size]

    tree_temp = DecisionTreeRegressor(random_state=42)
    tree_temp.fit(X_subset, y_subset)

    train_errors.append(mean_squared_error(y_subset, tree_temp.predict(X_subset)))
    test_errors.append(mean_squared_error(y_test, tree_temp.predict(X_test)))

plt.figure(figsize=(8, 5))
plt.plot(train_sizes, train_errors, label="Training Error")
plt.plot(train_sizes, test_errors, label="Testing Error")
plt.xlabel("Training Size")
plt.ylabel("MSE")
plt.title("Learning Curve – Detecting Overfitting")
plt.legend()
plt.grid(True)
plt.show()
